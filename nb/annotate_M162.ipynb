{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1159e410",
   "metadata": {},
   "source": [
    "## Walkthrough for annotating a mutation list with database data using annovar and clinscore\n",
    "\n",
    "#### Oftentimes you receive a mutation list of any sort and you need to annotate it with database info to have an idea about the position and relevance of the data. More than often, this task can be subdivided into several or all of the following steps:\n",
    "+ wrangle the data into the format (ID) Chr Start End Ref Alt .....\n",
    "+ if coords are on hg19, convert it to hg38 to use this annotation set (same procedure can be applied if converting back to hg19 is required+ annotate with annovar on command line using any of a set of databases\n",
    "+ apply clinscore calculation to get relevance of mutations in a clear (scalar) fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e094cda9",
   "metadata": {},
   "source": [
    "#### init paths and code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed10000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:26.448301Z",
     "start_time": "2022-02-06T16:22:26.430014Z"
    }
   },
   "outputs": [],
   "source": [
    "# some sensible settings for better output\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "\n",
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from script_utils import show_output\n",
    "\n",
    "# paths from environ file\n",
    "home = os.environ['HOME']\n",
    "# you need static files for the annovar annotation\n",
    "static_path = os.path.join(os.environ['STATIC'], \"annotation/clinical\")\n",
    "# here, set the working directory where your files are saved\n",
    "\n",
    "workdir = os.path.join(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7e693",
   "metadata": {},
   "source": [
    "### load mutation file and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306abe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:27.035919Z",
     "start_time": "2022-02-06T16:22:26.903180Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(workdir, \"testdata/test_mutations_hg19.xlsx\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518cb81",
   "metadata": {},
   "source": [
    "There are a lot of columns and information right now. The last rows are leftovers from the excel transformation so we get rid of them with iloc. To make things easy, we also remove every additional column right now and keep only the columns needed for annotation.\n",
    "The coords are somehow stored in the `Pos.` column and the mutation in the `Nuc Change` column. So do all this with `iloc`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f48b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:27.415154Z",
     "start_time": "2022-02-06T16:22:27.409007Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:16, [4,6]]\n",
    "# df = df.iloc[:15, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212cc403",
   "metadata": {},
   "source": [
    "### wrangle\n",
    "Now, we extract the relevant information with str.extract and some smart regex. This will be different everytime and if things get too complicated consider chaining several extracts and even to modify the source file itself. Try to be efficient here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fcf0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:28.015287Z",
     "start_time": "2022-02-06T16:22:27.988364Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:,[\"Start\", \"Chr\"]] = df['Pos.'].str.extract(r\"(?P<Chr>chr[0-9]+):g\\.(?P<Start>[0-9]+)\")\n",
    "df.loc[:,[\"Ref\", \"Alt\"]] = df['Nuc Change'].str.extract(r\"(?P<Ref>[ACTG]) -> (?P<Alt>[ACTG])\")\n",
    "df.loc[:, \"End\"] = df['Start']\n",
    "# df = df.loc[:,[\"Chr\", \"Start\", \"End\", \"Ref\", \"Alt\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d52462",
   "metadata": {},
   "source": [
    "### convert to hg38\n",
    "Although there are some tools that do that automatically, I still use the USCS website for conversion. For that, the coords have to be converted to the bed-format `Chr:Start-End`. This is always tedious and I use the helpers provided by the repo.\n",
    "Here are the steps:\n",
    "+ create the coords using `pos2bed` helper. Set option `as_string=True` and print the output for direct copying to the browser as it removes the index\n",
    "+ copy to the website and create the conversion\n",
    "+ reintroduce the hg38 coords into the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97020e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:28.621163Z",
     "start_time": "2022-02-06T16:22:28.604213Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyseq_utils import pos2bed\n",
    "print(pos2bed(df, as_string=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa355ea9",
   "metadata": {},
   "source": [
    "+ Now copy the coords to the clipboard and paste into the [uscs liftover website](https://genome.ucsc.edu/cgi-bin/hgLiftOver)\n",
    "+ click on `View conversions` and retrieve the file from your download folder. Should be something like `hglft_genome....be`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc08ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:29.245762Z",
     "start_time": "2022-02-06T16:22:29.225814Z"
    }
   },
   "outputs": [],
   "source": [
    "hg38 = pd.read_csv(os.path.join(home, \"Downloads/hglft_genome_1181f_fb3d20.bed\"), sep=\"\\t\", names=['hg38'])\n",
    "hg38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7611e",
   "metadata": {},
   "source": [
    "`bed2pos`reconverts the column into Chr Start End that can be reinserted into the dataframe. This only works by index, so make sure that your original df indices have not changed and are in a reset state!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd8189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:30.033484Z",
     "start_time": "2022-02-06T16:22:30.011143Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyseq_utils import bed2pos\n",
    "df.loc[:, [\"Chr\", \"Start\", \"End\"]] = bed2pos(hg38['hg38'])\n",
    "df = df.loc[:, ['Chr', 'Start', 'End', 'Ref', 'Alt']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29651991",
   "metadata": {},
   "source": [
    "### annotate data with annovar\n",
    "Annovar is a very comprehensive tool for annotation of mutations using various databases. See [here](https://annovar.openbioinformatics.org/en/latest/) for all you need to know. I provide a static file for genomic annotation that contains (among others) updated databases for use with annovar.\n",
    "For downloading the static files, do this from the root folder:\n",
    "+ `$ . setup/download_static.sh <path-to-static-folder>  # provide a folder for downloading and expanding ~40GB of data`\n",
    "+ for annovar to work, the path to the static folder has to be set in an environment variable STATIC: \n",
    "    * `$ export STATIC=<path-to-static-folder>`. \n",
    "    * For making this permanent, copy this line to your .bash_profile file in your HOME folder:\n",
    "    * (`$ echo \"export STATIC=<path-to-static-folder>\" >> \"${HOME}/.bash_profile`)\n",
    "\n",
    "This will take some time as it is downloading and unpacking a 40GB file!!\n",
    "\n",
    "Next, you have to configure the annovar_config.yaml file, giving it\n",
    "   + the absolute path to the annovar folder sitting in this repo at ./code/anno2019. This depends on where your repo is residing.\n",
    "   + the path in the STATIC folder to the annovar database (only change this if you moved the humandb folder somewhere else relative to the static folder)\n",
    "   + a list of databases from the annovar database to use for populating the mutations\n",
    "        * see the list of currently stored databases like so:`$ ls ${STATIC}/hg38/annotation/annovar/humandb/*.txt`\n",
    "        * if you want the database hg38_icgc29.txt to be used, just list \"icgc29\" in the yaml file\n",
    "\n",
    "Now, can run the annovar tool (run_annovar is a convenience wrapper around the command line tool written in perl), so you only have to worry once about providing the absolute path to the annovar code folder. You can see the large \n",
    "This will take some time depending on the list and size of both the mutations and the number and size of the databases used. You can see the long command line call in the cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d4e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:41.843508Z",
     "start_time": "2022-02-06T16:22:30.875865Z"
    }
   },
   "outputs": [],
   "source": [
    "from anno import run_annovar\n",
    "config_file = \"../configs/annovar_config.yaml\"\n",
    "                         \n",
    "df_anno = run_annovar(df, config_file, threads=10, cleanup=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9bad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T23:35:13.655571Z",
     "start_time": "2022-02-05T23:35:13.636232Z"
    }
   },
   "source": [
    "### The annovar result\n",
    "You can inspect the output and see that, depending on the used databases you have several new columns in your output dataframe\n",
    "But first, it would be wise to remove some of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ab79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:46.633893Z",
     "start_time": "2022-02-06T16:22:46.610844Z"
    }
   },
   "outputs": [],
   "source": [
    "df_anno[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57ffc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:47.560017Z",
     "start_time": "2022-02-06T16:22:47.531436Z"
    }
   },
   "outputs": [],
   "source": [
    "df_anno = df_anno.loc[:, ['Chr', 'Start', 'End', 'Ref', 'Alt', 'Func.ensGene34', 'Gene.ensGene34',\n",
    "        'ExonicFunc.ensGene34',\n",
    "       'cytoBand', 'gnomAD_exome_ALL', 'dbSNP154_AltFreq',\n",
    "       'Mut_ID', 'count', 'type',\n",
    "       'icgc29_ID', 'icgc29_Affected', 'CLNSIG']]\n",
    "df_anno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905d332",
   "metadata": {},
   "source": [
    "## include gene scores to clinscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef102508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T16:22:49.927792Z",
     "start_time": "2022-02-06T16:22:49.696721Z"
    }
   },
   "outputs": [],
   "source": [
    "from clinscore import get_cosmic_score\n",
    "\n",
    "clinscore_file = \"../configs/clinscoreLung.yaml\"\n",
    "df = get_cosmic_score(df_anno, cosmic_weights_file=clinscore_file, verbose=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae40343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T13:06:33.766689Z",
     "start_time": "2022-02-06T13:06:33.739877Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"/Users/martinszyska/Dropbox/Icke/Work/LO/Sequencing/LO_SequencingClaudia/M162-22AB_hg38.xlsx\", sheet_name=\"hg38_annotated\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
